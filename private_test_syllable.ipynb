{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"private_test_syllable.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IkCrrfay5DKe","outputId":"27db6633-c355-45f9-abca-b6d1669994d3"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5acznVS5H3b","outputId":"cad46840-c8ee-424d-b485-be8849fc148e"},"source":["%cd '/content/gdrive/MyDrive/VLSP2021-MRC'"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/.shortcut-targets-by-id/1-S62VF80vLD4deYL7ncHtff1BUGKdg56/VLSP2021-MRC\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HUNeWLv-5r7F","outputId":"31f94d54-5aca-4dff-8681-269e655b11a2"},"source":["!pip install transformers trankit"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 4.1 MB/s \n","\u001b[?25hCollecting trankit\n","  Downloading trankit-1.1.0-py3-none-any.whl (773 kB)\n","\u001b[K     |████████████████████████████████| 773 kB 45.6 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 35.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 64.9 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 88.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting huggingface-hub>=0.0.17\n","  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 6.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n","Collecting langid==1.1.6\n","  Downloading langid-1.1.6.tar.gz (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 57.0 MB/s \n","\u001b[?25hCollecting torch<1.8.0,>=1.6.0\n","  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n","\u001b[K     |████████████████████████████████| 776.8 MB 17 kB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 59.1 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from trankit) (3.17.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->trankit) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Building wheels for collected packages: langid\n","  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941187 sha256=5cf207b02634d73363435aadfc8d79e0e91e1c34b4babbda49c37639eb609f7b\n","  Stored in directory: /root/.cache/pip/wheels/2b/bb/7f/11e4db39477278161e882eadc46fb558949a28b13470fc74b8\n","Successfully built langid\n","Installing collected packages: pyyaml, torch, tokenizers, sentencepiece, sacremoses, langid, huggingface-hub, transformers, trankit\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0+cu111\n","    Uninstalling torch-1.9.0+cu111:\n","      Successfully uninstalled torch-1.9.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.10.0+cu111 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\n","torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\n","Successfully installed huggingface-hub-0.0.19 langid-1.1.6 pyyaml-6.0 sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.10.3 torch-1.7.1 trankit-1.1.0 transformers-4.11.3\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gzEFunJ5O5u","outputId":"23877b29-42bf-490b-c71c-52e647a0ec99"},"source":["import string\n","import json\n","from trankit import Pipeline\n","from tqdm import tqdm\n","\n","punctuation = string.punctuation + '…'\n","\n","p = Pipeline('vietnamese', embedding='xlm-roberta-large')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading pretrained XLM-Roberta, this may take a while...\n","Loading tokenizer for vietnamese\n","Loading tagger for vietnamese\n","Loading lemmatizer for vietnamese\n","Loading NER tagger for vietnamese\n","==================================================\n","Active language: vietnamese\n","==================================================\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z0zenDtI5VH0","outputId":"cb51204d-d491-423f-d8a4-6006824ece0f"},"source":["original_data = json.load(open('/content/gdrive/MyDrive/Data/DataVLSP/Private_data/private_test.json', 'r'))\n","\n","for article in tqdm(original_data['data']):\n","    title = article['title']\n","    for paragraph in article['paragraphs']:\n","        context = paragraph['context']\n","        context = ' '.join(context.split())\n","        tokenized_context = p.tokenize(context)\n","        for qa in paragraph['qas']:\n","            question = qa['question']\n","            question = ' '.join(question.split())\n","            tokenized_question = p.tokenize(question, is_sent=True)\n","            qa['question'] = ' '.join([token['text'].replace(' ', '_') for token in tokenized_question['tokens']])\n","        paragraph['context'] = ' '.join([token['text'].replace(' ', '_') for sentence in tokenized_context['sentences'] for token in sentence['tokens']])\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 49/49 [16:48<00:00, 20.58s/it]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TA8sh9BEDGWw","outputId":"119d6515-ac2c-4bff-8050-d952123f6628"},"source":["for article in tqdm(original_data['data']):\n","    title = article['title']\n","    for paragraph in article['paragraphs']:\n","        context = paragraph['context']\n","        for qa in paragraph['qas']:\n","            question = qa['question']\n","            qa['question'] = question.replace('_', ' ')\n","        paragraph['context'] = context.replace('_', ' ')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 49/49 [00:00<00:00, 7410.70it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"burx_3hg4_6y"},"source":["def convert_test_format(original_data, file_out):\n","    data = original_data['data']\n","\n","    for i in range(len(data)):\n","      for j in range(len(data[i]['paragraphs'])):\n","        for k in range(len(data[i]['paragraphs'][j]['qas'])):\n","          data[i]['paragraphs'][j]['qas'][k]['answers'] = []\n","          data[i]['paragraphs'][j]['qas'][k]['is_impossible'] = False\n","\n","    public_test = {'version':'private test', \"data\": data}\n","    with open(file_out, 'w', encoding='utf-8') as outfile:\n","        json.dump(public_test, outfile ,ensure_ascii=False,indent=4)\n","\n","convert_test_format(original_data,\"/content/gdrive/MyDrive/Data/DataVLSP/Private_data/private_test_syllable.json\")"],"execution_count":null,"outputs":[]}]}